{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SENet\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Convolution -> Feature recalibration\n",
    "\n",
    "U : squeeze operation\n",
    "\n",
    "Excitation operation : sample-specific activation\n",
    "\n",
    "\n",
    "![Imgur](https://i.imgur.com/9UFjxDA.png)\n",
    "\n",
    "\n",
    "SENet 장점 : 기존 네트워크에 바로 적용 가능\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Related work\n",
    "\n",
    "Deep architectures : VGGNet, BN, ResNet, Highway network, Grouped convolutions, Multi-branch convolution etc.\n",
    "\n",
    "Attention and gating mechanisms\n",
    "\n",
    "Attention : input signal에서 가장 효율적인 부분에 자원 분배 가능하게 해줌 - localization 등에 응용\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squeeze and Excitation Blocks\n",
    "\n",
    "$${ { F }_{ tr }:X\\rightarrow U,X\\in { R }^{ { H }^{ ' }\\times { W }^{ ' }\\times { C }^{ ' } },U\\in { R }^{ { H }\\times { W }\\times { C } } }$$\n",
    "\n",
    "${ F }_{ tr }$ : Convoluation 연산\n",
    "\n",
    "$V=\\left[ { v }_{ 1 },{ v }_{ 2 },...,{ v }_{ c } \\right] $ : 필터 집합 $V$와 각 필터의 파라미터. ${ v }_{ c }$는 c번째 필터의 파라미터\n",
    "\n",
    "$U=\\left[ { u }_{ 1 },{ u }_{ 2 },...,{ u }_{ C } \\right]$ : $ { F }_{ tr }$을 통과한 결과물\n",
    "\n",
    "$${ u }_{ c }={ u }_{ c }\\ast X=\\sum _{ s=1 }^{ { C }^{ ' } }{ { v }_{ c }^{ s }\\ast { X }^{ s } } $$\n",
    "\n",
    "${ v }_{ c }=\\left[ { v }_{ c }^{ 1 },{ v }_{ c }^{ 2 },...,{ v }_{ c }^{ C' } \\right] $ : ${ v }_{ c }^{ s }$ is 2D spatial kernel\n",
    "\n",
    "${ X }=\\left[ { x }^{ s },{ x }^{ 2 },...,x^{ C' } \\right] $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squeeze: Global Information Embedding\n",
    "\n",
    "네트워크 시작 부분일수록 receptive field가 작기 때문에 너무 국소적인 부분만 보는 현상이 생김. 이런 문제를 해결하기 위한 방법이 squeeze.\n",
    "\n",
    "squeeze는 global spatial information을 channel descriptor로 압축시키는 것. 이를 위하여 global average pooling을 실시함.\n",
    "\n",
    "$${ z }_{ c }={ F }_{ sq }\\left( { u }_{ c } \\right) =\\frac { 1 }{ H\\times W } \\sum _{ i=1 }^{ H }{ \\sum _{ j=1 }^{ W }{ { u }_{ c }(i,j) }  } $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excitation: Adaptive Recalibration\n",
    "\n",
    "Excitation은 squeeze operation을 통과해서 압축된 정보들을 사용하기 위한 작업. 목적은 channel-wise d ependency를 완전히 잡아내는 것.\n",
    "\n",
    "- Flexible (채널 간 비선형적인 상호작용을 학습해야함)\n",
    "- Must learn non-mutually-exclusive relationship\n",
    "\n",
    "이를 위해서 sigmoid activation을 사용.\n",
    "\n",
    "$$s={ F }_{ ex }\\left( z,W \\right) =\\sigma ({ W }_{ 2 }\\delta ({ W }_{ 1 }z))$$\n",
    "\n",
    "위 식에서 델타는 ReLU.\n",
    "모델 복잡성과 aid generalization을 위하여 FC layer 2개를 활성함수 옆에 쌓아서 bottleneck(ResNet에서 나온 그 보틀넥)을 만들었음. 여기서 ${W}_{1}$은 reduction ratio $\\gamma $를 사용하여 차원수를 줄임. ${W}_{2}$를 통과하면 차원수가 늘어나게 됨.\n",
    "\n",
    "최종 아웃풋은 아래와 같음\n",
    "\n",
    "$${ \\tilde { x }  }_{ c }={ F }_{ scale }({ u }_{ c },{ s }_{ c })=s_{ c }\\cdot { u }_{ c }$$\n",
    "\n",
    "\n",
    "${ \\tilde { X }  }=\\left[ { \\tilde { x }  }_{ 1 },{ \\tilde { x }  }_{ 2 },...,{ \\tilde { x }  }_{ C } \\right] $\n",
    "\n",
    "${ F }_{ scale }|(u_{ c },{ s }_{ c })$ : Channel-wise multiplication between feature map and scalar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplars: SE-Inception and SE-ResNet\n",
    "\n",
    "SE block의 장점 중 하나는 felxity로 어떤 convolution에도 쉽게 적용할 수 있다는 것. VGG나 AlexNet에도 바로 적용이 가능함.\n",
    "\n",
    "![Imgur](https://i.imgur.com/NyGsIbX.png)\n",
    "\n",
    "![Imgur](https://i.imgur.com/lqkeLxF.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Computational Complexity\n",
    "\n",
    "모델 복잡도와 성능은 trade-off 관계임. reduction ratio $\\gamma$를 모든 실험에서 16으로 셋팅하였음. \n",
    "\n",
    "실험 모델은 ResNet-50, SE-ResNet-50을 썼고, SE-ResNet-50이 ResNet-101에 근접하는 매우좋은 성능을 보여줌. \n",
    "\n",
    "- ResNet-50 : ~3.86 GFLOPS for 224 x 224 input image\n",
    "- SE-ResNet-50 : ~3.87 GFLOPS -> 상대적으로 0.26%만 증가!\n",
    "\n",
    "이는 squeeze, excitation, channel-wise scaling 전부 계산복잡도가 높지 않기 때문임\n",
    "\n",
    "타이탄 X 썼을 때, 256 mini batch size 기준 ResNet-50은 190ms, SE-ResNet-50은 206ms가 걸렸음\n",
    "\n",
    "$$\\frac { 2 }{ r } \\sum _{ s=1 }^{ S }{ { N }_{ s }\\cdot { C }_{ s }^{ 2 } } $$\n",
    "\n",
    "위 식은 SE block을 추가했을 때 추가되는 파라미터의 수임.\n",
    "\n",
    "- $S$ : number of stages\n",
    "- ${C}_{s}$ : dimension of the output channels\n",
    "- ${N}_{s}$ : repepated block number for stage s\n",
    "\n",
    "SE-ResNet-50이 ResNet-50 대비 ~2.5 million 개의 추가적인 파라미터가 들어감(ResNet-50만 따지면 25 million).  \n",
    "마지막 단의 SE block은 사실 지워도 큰 차이가 없었음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "- ImageNet data\n",
    "- Random-size cropping to 224 x 224\n",
    "- Random horizontal lflipping\n",
    "- Normalize input image through mean channel subtraction\n",
    "- Data balancing for mini batch sampling\n",
    "- Momentum 0.9, batch size 1024\n",
    "- Learning rate 0.6 -> x10 every 30 epochs\n",
    "- 100 epochs\n",
    "- Testing : center crop evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "### ImageNet classification\n",
    "\n",
    "![Imgur](https://i.imgur.com/BWo3s95.png)\n",
    "\n",
    "![Imgur](https://i.imgur.com/MiibvZx.png)\n",
    "\n",
    "파라미터 증가량은 매우 적은데도 불구하고 SE block을 적용하면 굉장히 성능이 좋아지는 것을 확인할 수 있음.  \n",
    "SE-ResNet-50이 ResNet-50에 비교해서 0.86% 좋아짐\n",
    "\n",
    "![Imgur](https://i.imgur.com/a88ocU9.png)\n",
    "\n",
    "망이 깊은 구조에 사용해도 성능 증가 효과가 상당함. 이는 deep한 구조의 모델에서 베이스로 넣기 충분희 유의미한 결과임\n",
    "\n",
    "![Imgur](https://i.imgur.com/3ywuaXK.png)\n",
    "\n",
    "SOTA들과 비교해서도 TOP 성능을 보여줌. (2017 ILSVRC 우승)\n",
    "\n",
    "![Imgur](https://i.imgur.com/VQun2eY.png)\n",
    "\n",
    "Scene classification, object detection 모두 좋은 성능을 보임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis and Interpreation\n",
    "\n",
    "#### Reduction ratio\n",
    "\n",
    "Reduction ratio $r$은 계산복잡도와 모델 용량을 결정하는 매우 중요한 하이퍼파라미터. Table 7을 보면 값의 변화에 따른 에러 변화량이 나와있음. 확실히 커지면 에러가 커지고 반면에 파라미터 수는 줄어듦. \n",
    "\n",
    "![Imgur](https://i.imgur.com/HysviWp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The role of Excitation\n",
    "\n",
    "![Imgur](https://i.imgur.com/TxLUc34.png)\n",
    "\n",
    "\n",
    "각 클래스별 분포가 블럭이 바뀜에따라  어떻게 되는지 측정해봄.\n",
    "Average activations for fifty uniformly sampled channels in the last SE block.\n",
    "\n",
    "- 하위 부분일수록 거의 비슷한 분포를 따름. 이는 이는 초반 부분에 중요한 feature channel들이 공유가 된다고 할 수 있음\n",
    "- 깊이가 깊어질수록 서로 달라짐. SE_4_6 이랑 SE 5_1 예시. 이는 SE block이 feature extraction과 feature specialization을 잘 하고있다는 것을 보여줌\n",
    "- 네트워크 마지막 부분(SE_5_3 : classifier 직전)을 보면 클래스가 달라도 유사한 분포를 보여주고 있음. Recalibration을 제대로 못함. 파라미터 축소를 위해 제거하는게 나음\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
