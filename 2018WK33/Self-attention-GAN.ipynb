{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-attention GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "\n",
    "## 1.1 GAN 소개 및 단점\n",
    "- GAN은 성공적이였으나 일부 클래스에 대해 문제점이 있음\n",
    "- GAN은 텍스처 위주 클래스(바다, 하늘 등)는 잘 생성\n",
    "- 그러나 geometry가 중요한 클래스 (동물 등) 는 한계가 있음\n",
    "    - geometric or structural patterns 표현은 잘 못함\n",
    "    - 생성할 때 동물의 texture만은 실제같음\n",
    "- 한계에 대한 이유\n",
    "    - GAN에서는 이미지의 다양한 위치에 다한 dependency를 모델링하기 위해서 convolution에 많이 의지함\n",
    "    - convolution의 receptive field의 범위는 local로 제한됨.\n",
    "    - 따라서 거리가 먼 region 사이의 dependency 모델링은 convolution layer를 몇 차례 거친 후에 가능함\n",
    "    - 이러한 점은 long-term dependency를 학습하는데 장애가 될 수 있음\n",
    "        - small model: not able to represnet dependency\n",
    "        - optimzation: 여러 conv layer를 거쳐 dependency를 잘 표현하는 parameter를 찾아내는데 어려움을 겪을 수 있음\n",
    "        - paraemterization이 통계적으로 기반이 약하고, unseen input에 대해서 성능이 떨어질 수 있음\n",
    "        - kerenl size 증가: 모델의 capacity가 커져서 dependency를 표현하기 쉬워질 수 있지만, convolution의 근본 목적인 계산량 감소와 통계적 효율성을 포기 해야함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Self-attention에 대해서\n",
    "- long range dependency와 computational cost 사이의 balance가 좋음\n",
    "- self attention 모듈은 적은 코스트로 각 픽셀의 전체 영역에 대한 attention vector를 만들 수 있다.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/SeongHwan-Hong/img_host/master/SelfAttention/SS1.PNG\" alt=\"drawing\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Propose\n",
    "- Self-Attention Generative Adversarial Networks\n",
    "    - self attention 메카니즘을 기존 GAN에 도입함\n",
    "    - self attention 기존 convolution의 단점을 보완할 수 있고, 이미지에서 긴 범위와 여러 단계의 의존에 대해 모델링 할 수 있음\n",
    "    - \n",
    "- GAN의 성능 향상과 관련된 최근의 insight 도입\n",
    "    - spectral normalization technique\n",
    "        - 기존에는 discrimnator에만 도입되었지만 generator에 도입함\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Related Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 GAN\n",
    "- 생 략 - \n",
    "\n",
    "## 2.2 attention\n",
    "\n",
    "- 생 략 - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 대부분의 이미지 생성 GAN은 conv layer가 존재\n",
    "- conv layer는 local neighbotr에 대한 정보를 제공함\n",
    "- 따라서 conv 만으로 long-range dependency를 모델링 하는 것은 비효율적임\n",
    "- non-local network 모델을 이용할 것임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.1 Step1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- input x는 f와 g로 변환됨\n",
    "- $f(x) = W_fx$\n",
    "- $g(x) = W_gx$\n",
    "- $W_f, W_g$는 1x1 conv로 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/SeongHwan-Hong/img_host/master/SelfAttention/SS3.PNG\" alt=\"drawing\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.2 Step2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/SeongHwan-Hong/img_host/master/SelfAttention/SS5.PNG\" alt=\"drawing\" style=\"width: 900px;\"/>\n",
    "<img src=\"https://raw.githubusercontent.com/SeongHwan-Hong/img_host/master/SelfAttention/SS6.PNG\" alt=\"drawing\" style=\"width: 900px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.3 Step3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/SeongHwan-Hong/img_host/master/SelfAttention/SS7.PNG\" alt=\"drawing\" style=\"width: 900px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 ETC\n",
    "\n",
    "- $y_i = \\gamma o_i + x_i$\n",
    "- $\\gamma$는 학습 초기에는 0으로 설정\n",
    "    - 학습이 진행 됨에 따라 $\\gamma$ 증가\n",
    "    - 0으로 할 경우 학습이 쉬우므로 늘려가면서 점차 학습\n",
    "\n",
    "- hinge loss 버전의 GAN loss를 사용함\n",
    "<img src=\"https://raw.githubusercontent.com/SeongHwan-Hong/img_host/master/SelfAttention/SS9.PNG\" alt=\"drawing\" style=\"width: 900px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Techniques to stabilize GAN training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. spectral normalization, \n",
    "2. two-timescale update rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Spectral normalization for both generator and discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- constrains the Lipschitz constant of the discriminator by restricting the spectral norm of each layer\n",
    "- Spectral normalization 기법을 generator에도 적용\n",
    "- Generator에 적용했을 경우 emprical하게 잘 됨을 확인\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Imbalanced learning rate for generator and discriminator updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- regularized discriminator는 학습이 느림\n",
    "- TTUR(Two time-scale update rule for training GAN)을 사용\n",
    "- Wall clock time 기준으로 더 나은 효율을 보임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LSVRC2012 데이터 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. stabilizing GAN training을 비교하기 위한 실험\n",
    "2. proposed self-attention mechanism is investigated\n",
    "3. 현재 sota와 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation metrics.\n",
    "- Inception score\n",
    "- Fréchet Inception distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 TTUR, spectral normalization의 효과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/SeongHwan-Hong/img_host/master/SelfAttention/SS10.PNG\" alt=\"drawing\" style=\"width: 900px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Self-attention 효과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/SeongHwan-Hong/img_host/master/SelfAttention/SS11.PNG\" alt=\"drawing\" style=\"width: 900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/SeongHwan-Hong/img_host/master/SelfAttention/SS12.PNG\" alt=\"drawing\" style=\"width: 900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 sota와 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/SeongHwan-Hong/img_host/master/SelfAttention/SS13.PNG\" alt=\"drawing\" style=\"width: 900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/SeongHwan-Hong/img_host/master/SelfAttention/SS14.PNG\" alt=\"drawing\" style=\"width: 900px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
